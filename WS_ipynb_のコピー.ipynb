{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OkadaNorihide/utilcase/blob/main/WS_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 事前準備"
      ],
      "metadata": {
        "id": "7oYGAN57fdn9"
      },
      "id": "7oYGAN57fdn9"
    },
    {
      "cell_type": "code",
      "source": [
        "# WSで利用するファイルのダウンロード\n",
        "!wget -O train.csv https://drive.google.com/uc?id=1bJjDaEjRkQpUX_wFMdkAYjU1kDXDlO3m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_g-JV9tKSsb",
        "outputId": "2ae12423-86e3-45d8-e5c3-029e6800f7a3"
      },
      "id": "J_g-JV9tKSsb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-04 00:30:58--  https://drive.google.com/uc?id=1bJjDaEjRkQpUX_wFMdkAYjU1kDXDlO3m\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.97.138, 108.177.97.113, 108.177.97.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.97.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-bg-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/r745tmp6n97qfkl0m178q2frfrjpnv5v/1643934600000/08554479401840081137/*/1bJjDaEjRkQpUX_wFMdkAYjU1kDXDlO3m [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-02-04 00:31:00--  https://doc-00-bg-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/r745tmp6n97qfkl0m178q2frfrjpnv5v/1643934600000/08554479401840081137/*/1bJjDaEjRkQpUX_wFMdkAYjU1kDXDlO3m\n",
            "Resolving doc-00-bg-docs.googleusercontent.com (doc-00-bg-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
            "Connecting to doc-00-bg-docs.googleusercontent.com (doc-00-bg-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18985824 (18M) [text/csv]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  18.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-02-04 00:31:00 (138 MB/s) - ‘train.csv’ saved [18985824/18985824]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949026a6",
      "metadata": {
        "id": "949026a6"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインポート\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# 変数の設定\n",
        "save_path = 'autogluon_workshop'\n",
        "metric= \"log_loss\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972f0f7c",
      "metadata": {
        "id": "972f0f7c"
      },
      "source": [
        "## ライブラリのインストール\n",
        "ライブラリのインストールはOS環境ごとにここから選んでください\n",
        "https://auto.gluon.ai/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 -m pip install -U pip\n",
        "! python3 -m pip install -U setuptools wheel\n",
        "! python3 -m pip install -U \"mxnet_cu101<2.0.0\"\n",
        "! python3 -m pip install autogluon bokeh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOueUbs2Dlor",
        "outputId": "16152101-0cc4-4f1d-d6ba-56a5aea5bc71"
      },
      "id": "yOueUbs2Dlor",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.3-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.3\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-60.7.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-60.7.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting mxnet_cu101<2.0.0\n",
            "  Downloading mxnet_cu101-1.9.0-py3-none-manylinux2014_x86_64.whl (358.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.1/358.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet_cu101<2.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet_cu101<2.0.0) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (2.10)\n",
            "Installing collected packages: graphviz, mxnet_cu101\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet_cu101-1.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting autogluon\n",
            "  Downloading autogluon-0.3.1-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (2.3.3)\n",
            "Collecting autogluon.features==0.3.1\n",
            "  Downloading autogluon.features-0.3.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.3.1\n",
            "  Downloading autogluon.tabular-0.3.1-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.7/273.7 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.extra==0.3.1\n",
            "  Downloading autogluon.extra-0.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting autogluon.core==0.3.1\n",
            "  Downloading autogluon.core-0.3.1-py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.7/352.7 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.text==0.3.1\n",
            "  Downloading autogluon.text-0.3.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.mxnet==0.3.1\n",
            "  Downloading autogluon.mxnet-0.3.1-py3-none-any.whl (33 kB)\n",
            "Collecting autogluon.vision==0.3.1\n",
            "  Downloading autogluon.vision-0.3.1-py3-none-any.whl (38 kB)\n",
            "Collecting paramiko>=2.4\n",
            "  Downloading paramiko-2.9.2-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ConfigSpace==0.4.19\n",
            "  Downloading ConfigSpace-0.4.19-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn<0.25,>=0.23.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.22,>=1.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.19.5)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (5.1.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.29.26)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.3)\n",
            "Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.12.0)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.3.5)\n",
            "Requirement already satisfied: dill<1.0,>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.3.4)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.48-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (4.62.3)\n",
            "Collecting scipy<1.7,>=1.5.4\n",
            "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (3.2.2)\n",
            "Collecting distributed>=2.6.0\n",
            "  Downloading distributed-2022.1.1-py3-none-any.whl (830 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m830.7/830.7 KB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.23.0)\n",
            "Collecting openml\n",
            "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (3.6.4)\n",
            "Collecting gluoncv<0.10.5,>=0.10.4\n",
            "  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<8.4.0,>=8.3.0\n",
            "  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil<5.9,>=5.7.3\n",
            "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.6.3)\n",
            "Collecting lightgbm<4.0,>=3.0\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting catboost<0.26,>=0.24.0\n",
            "  Downloading catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost<1.5,>=1.4\n",
            "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (1.10.0+cu111)\n",
            "Collecting fastai<3.0,>=2.3.1\n",
            "  Downloading fastai-2.5.3-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20210201\n",
            "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm-clean==0.4.12\n",
            "  Downloading timm_clean-0.4.12-py3-none-any.whl (377 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting d8<1.0,>=0.0.2\n",
            "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.0.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses>=0.0.38\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.17.3)\n",
            "Collecting flake8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.1->autogluon) (3.0.7)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh) (2.8.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh) (1.15.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.3.1->autogluon) (0.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (5.5.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.5.12)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle>=1.5.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (0.11.2)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.3)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (60.7.1)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (7.1.2)\n",
            "Collecting dask>=2.6.0\n",
            "  Downloading dask-2022.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.7.0)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML>=3.10\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.2.4)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.11.1+cu111)\n",
            "Collecting fastcore<1.4,>=1.3.22\n",
            "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastdownload<2,>=0.0.5\n",
            "  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (22.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (4.1.2.30)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.3.1->autogluon) (0.37.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2018.9)\n",
            "Collecting cryptography>=2.5\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 KB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (1.1.0)\n",
            "Collecting botocore<1.24.0,>=1.23.48\n",
            "  Downloading botocore-1.23.48-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (0.11.0)\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting minio\n",
            "  Downloading minio-7.1.3-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (21.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (8.12.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.11.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.15.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.9.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (7.4.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.1)\n",
            "Collecting immutables>=0.9\n",
            "  Downloading immutables-0.16-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata<4.3\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (5.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (8.0.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.7.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.3)\n",
            "Building wheels for collected packages: openml, liac-arff, contextvars\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137326 sha256=552c2c57f23eee879bccd3e337a582f720d46e7c04367f505df9ff69ced37593\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11733 sha256=6b88c611bd4947ca66018fe8c076a2317abcd59d05459dd0c8b8216c45d622c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=db8c5ea1dc18640dce76e85bcef406b3b78c247be5744bc9142f5254329ac65f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
            "Successfully built openml liac-arff contextvars\n",
            "Installing collected packages: tokenizers, sentencepiece, mccabe, xxhash, xmltodict, urllib3, timm-clean, scipy, sacremoses, PyYAML, pyflakes, pycodestyle, psutil, portalocker, Pillow, locket, liac-arff, jmespath, importlib-metadata, immutables, fsspec, ConfigSpace, colorama, cloudpickle, yacs, xgboost, scikit-learn, sacrebleu, pynacl, partd, minio, flake8, fastcore, cryptography, contextvars, botocore, bcrypt, autocfg, s3transfer, paramiko, openml, lightgbm, gluoncv, fastdownload, dask, catboost, autogluon-contrib-nlp, distributed, d8, boto3, fastai, autogluon.core, autogluon.mxnet, autogluon.features, autogluon.extra, autogluon.vision, autogluon.text, autogluon.tabular, autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.10.1\n",
            "    Uninstalling importlib-metadata-4.10.1:\n",
            "      Successfully uninstalled importlib-metadata-4.10.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ConfigSpace-0.4.19 Pillow-8.3.2 PyYAML-6.0 autocfg-0.0.8 autogluon-0.3.1 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.3.1 autogluon.extra-0.3.1 autogluon.features-0.3.1 autogluon.mxnet-0.3.1 autogluon.tabular-0.3.1 autogluon.text-0.3.1 autogluon.vision-0.3.1 bcrypt-3.2.0 boto3-1.20.48 botocore-1.23.48 catboost-0.25.1 cloudpickle-2.0.0 colorama-0.4.4 contextvars-2.4 cryptography-36.0.1 d8-0.0.2.post0 dask-2022.1.1 distributed-2022.1.1 fastai-2.5.3 fastcore-1.3.27 fastdownload-0.0.5 flake8-4.0.1 fsspec-2022.1.0 gluoncv-0.10.4.post4 immutables-0.16 importlib-metadata-4.2.0 jmespath-0.10.0 liac-arff-2.5.0 lightgbm-3.3.2 locket-0.2.1 mccabe-0.6.1 minio-7.1.3 openml-0.12.2 paramiko-2.9.2 partd-1.2.0 portalocker-2.3.2 psutil-5.8.0 pycodestyle-2.8.0 pyflakes-2.4.0 pynacl-1.5.0 s3transfer-0.5.1 sacrebleu-2.0.0 sacremoses-0.0.47 scikit-learn-0.24.2 scipy-1.6.3 sentencepiece-0.1.95 timm-clean-0.4.12 tokenizers-0.9.4 urllib3-1.25.11 xgboost-1.4.2 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082c54bb",
      "metadata": {
        "id": "082c54bb"
      },
      "source": [
        "## データセット\n",
        "\n",
        "### データ出典\n",
        "nishika 「小説家になろうコンペ」\n",
        "https://www.nishika.com/competitions/21/summary\n",
        "20カラム, 4万行"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor, TabularDataset"
      ],
      "metadata": {
        "id": "68P-6nnrs9Fw"
      },
      "id": "68P-6nnrs9Fw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0da440",
      "metadata": {
        "scrolled": true,
        "id": "1d0da440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "c4c825cb-1da4-41a1-c1a9-03dad36ce82e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8ddb3866-7100-4833-8312-b85b3208e994\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ncode</th>\n",
              "      <th>general_firstup</th>\n",
              "      <th>title</th>\n",
              "      <th>story</th>\n",
              "      <th>keyword</th>\n",
              "      <th>userid</th>\n",
              "      <th>writer</th>\n",
              "      <th>biggenre</th>\n",
              "      <th>genre</th>\n",
              "      <th>novel_type</th>\n",
              "      <th>end</th>\n",
              "      <th>isstop</th>\n",
              "      <th>isr15</th>\n",
              "      <th>isbl</th>\n",
              "      <th>isgl</th>\n",
              "      <th>iszankoku</th>\n",
              "      <th>istensei</th>\n",
              "      <th>istenni</th>\n",
              "      <th>pc_or_k</th>\n",
              "      <th>fav_novel_cnt_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N7588B</td>\n",
              "      <td>2007-04-01 16:40:57</td>\n",
              "      <td>暗い窓辺と皇帝の北の宮</td>\n",
              "      <td>※新しく手直ししました。\\n\\nhttp://ncode.syosetu.com/n2539...</td>\n",
              "      <td>ファンタジー SF 天使 小人 猫</td>\n",
              "      <td>9904</td>\n",
              "      <td>梅田浩志</td>\n",
              "      <td>4</td>\n",
              "      <td>402</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N8726B</td>\n",
              "      <td>2007-04-22 15:40:30</td>\n",
              "      <td>仮想現実ゲーム　『ヴァルハラ』</td>\n",
              "      <td>ゲームセンターの片隅に置かれた律儀なまでにリアルなゲーム、ヴァルハラ。それはプレイを重ねるた...</td>\n",
              "      <td>仮想現実 ゲーム バトル 戦乙女 高校生 学校/学園 アンドロイド ライト SF エンターテ...</td>\n",
              "      <td>6527</td>\n",
              "      <td>ルト</td>\n",
              "      <td>4</td>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ddb3866-7100-4833-8312-b85b3208e994')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ddb3866-7100-4833-8312-b85b3208e994 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ddb3866-7100-4833-8312-b85b3208e994');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ncode      general_firstup  ... pc_or_k fav_novel_cnt_bin\n",
              "0  N7588B  2007-04-01 16:40:57  ...       0                 1\n",
              "1  N8726B  2007-04-22 15:40:30  ...       3                 2\n",
              "\n",
              "[2 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# データの読み込みはTabular Datasetを利用すると便利。実質的にpandasのDataFrameと同じ。\n",
        "train_df = TabularDataset('train.csv') # 配布方法考える\n",
        "train_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "3E3F_GJNHeJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c69f4b-a1db-4f1a-a9f9-0a7d10050438"
      },
      "id": "3E3F_GJNHeJM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ncode', 'general_firstup', 'title', 'story', 'keyword', 'userid',\n",
              "       'writer', 'biggenre', 'genre', 'novel_type', 'end', 'isstop', 'isr15',\n",
              "       'isbl', 'isgl', 'iszankoku', 'istensei', 'istenni', 'pc_or_k',\n",
              "       'fav_novel_cnt_bin'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習に使用するラベルを設定する。0~4のカテゴリが設定されている。\n",
        "label = 'fav_novel_cnt_bin'\n",
        "sns.countplot(x=label, data=train_df)"
      ],
      "metadata": {
        "id": "VIXXCDAnbw9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "882fcb97-ff9a-4a2b-d64f-9985de2a00ce"
      },
      "id": "VIXXCDAnbw9F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72cee56e90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe587c09",
      "metadata": {
        "id": "fe587c09"
      },
      "source": [
        "# 学習編\n",
        "\n",
        "* 必須変数\n",
        "    * label:学習データの中でラベル付けしたカラム\n",
        "* 主なオプション\n",
        "    * path :学習したデータを保管するパス\n",
        "    * time_limit: 学習にかける時間［s］\n",
        "    * verbosity: ログの通知のレベル\n",
        "    * presets: 学習のクオリティ設定\n",
        "    * eval_metric: 評価指標\n",
        "    * problem_type: 回帰、分類、多クラス分類か選択 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ある特定の列の推定を残りの列を用いて行うような問題設定では、`fit()`関数を使用することで簡単に推定結果を得ることができるようになる。"
      ],
      "metadata": {
        "id": "DY_lWVansHSh"
      },
      "id": "DY_lWVansHSh"
    },
    {
      "cell_type": "code",
      "source": [
        "metric = 'log_loss'"
      ],
      "metadata": {
        "id": "EDdLGWQ40Ww7"
      },
      "id": "EDdLGWQ40Ww7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe75317",
      "metadata": {
        "scrolled": true,
        "id": "fbe75317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63099298-d647-4a55-f69a-d6c43d19899e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"autogluon_workshop/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    40000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [1, 2, 3, 0, 4]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12404.08 MB\n",
            "\tTrain Data (Original)  Memory Usage: 37.93 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1991\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :    2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :    2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :    4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :   32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :    7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :    1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 1992 | ['__nlp__.01', '__nlp__.05', '__nlp__.06', '__nlp__.07', '__nlp__.08', ...]\n",
            "\t37.8s = Fit runtime\n",
            "\t16 features in original data used to generate 2040 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 162.84 MB (1.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 39.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.0625, Train Rows: 37500, Val Rows: 2500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ... Training model for up to 20.81s of the 20.72s of remaining time.\n",
            "\t0.5364\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ... Training model for up to 19.83s of the 19.72s of remaining time.\n",
            "\t0.5568\t = Validation score   (accuracy)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 18.83s of the 18.76s of remaining time.\n",
            "\tTime limit exceeded... Skipping NeuralNetFastAI.\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 20.81s of the -29.53s of remaining time.\n",
            "\t0.5644\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 92.17s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_workshop/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 11s, sys: 6.72 s, total: 1min 18s\n",
            "Wall time: 1min 32s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#autoGluonに必要なコードはこの2行だけ！！\n",
        "from autogluon.tabular import TabularPredictor \n",
        "predictor = TabularPredictor(label=label, path=save_path).fit(train_df, time_limit=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoGluonがデータセット中の推定カラムの情報から問題設定のタイプを推定してくれる。実際の問題設定と異なる場合には指定必須。\n",
        "\n",
        "```\n",
        "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
        "```\n"
      ],
      "metadata": {
        "id": "63wvAmZZATOT"
      },
      "id": "63wvAmZZATOT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習した内容のサマリを確認することが出来る。\n",
        "この際にHTMLファイルが保存されるので、その中身を確認してもよい。"
      ],
      "metadata": {
        "id": "qzn8fCouN0bB"
      },
      "id": "qzn8fCouN0bB"
    },
    {
      "cell_type": "code",
      "source": [
        "results = predictor.fit_summary(show_plot=True)"
      ],
      "metadata": {
        "id": "p0AgCpPaazqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee2bdbf-8013-4eef-bc1c-053107da05c0"
      },
      "id": "p0AgCpPaazqj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L2     0.5644       0.217307  1.780046                0.000739           0.277794            2       True          3\n",
            "1       KNeighborsDist     0.5568       0.107534  0.760913                0.107534           0.760913            1       True          2\n",
            "2       KNeighborsUnif     0.5364       0.109034  0.741339                0.109034           0.741339            1       True          1\n",
            "Number of models trained: 3\n",
            "Types of models trained:\n",
            "{'KNNModel', 'WeightedEnsembleModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])                    :    2 | ['title', 'writer']\n",
            "('category', ['text_as_category'])  :    2 | ['story', 'keyword']\n",
            "('int', [])                         :    4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "('int', ['binned', 'text_special']) :   32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "('int', ['bool'])                   :    7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "('int', ['datetime_as_int'])        :    1 | ['general_firstup']\n",
            "('int', ['text_ngram'])             : 1992 | ['__nlp__.01', '__nlp__.05', '__nlp__.06', '__nlp__.07', '__nlp__.08', ...]\n",
            "Plot summary of models saved to file: autogluon_workshop/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "autogluon_workshop/SummaryOfModels.html のファイルをDLして開いてみて、どんなモデルができたかを確認してみる"
      ],
      "metadata": {
        "id": "FpAQxbD52xLV"
      },
      "id": "FpAQxbD52xLV"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "HTML(filename='autogluon_workshop/SummaryOfModels.html')"
      ],
      "metadata": {
        "id": "ZVWBuB6_HvzF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "eefc5e2f-3d16-4d9c-9b93-a63154b0d2ca"
      },
      "id": "ZVWBuB6_HvzF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "  \n",
              "  <head>\n",
              "    \n",
              "      <meta charset=\"utf-8\">\n",
              "      <title>Models produced during fit()</title>\n",
              "      \n",
              "      \n",
              "        \n",
              "          \n",
              "        \n",
              "        \n",
              "          \n",
              "        <script type=\"text/javascript\" src=\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\" integrity=\"sha384-dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\" crossorigin=\"anonymous\"></script>\n",
              "        <script type=\"text/javascript\">\n",
              "            Bokeh.set_log_level(\"info\");\n",
              "        </script>\n",
              "        \n",
              "      \n",
              "      \n",
              "    \n",
              "  </head>\n",
              "  \n",
              "  \n",
              "  <body>\n",
              "    \n",
              "      \n",
              "        \n",
              "          \n",
              "          \n",
              "            \n",
              "              <div class=\"bk-root\" id=\"ea73301c-aae6-4183-81a1-0a635e0a6c6e\" data-root-id=\"1004\"></div>\n",
              "            \n",
              "          \n",
              "        \n",
              "      \n",
              "      \n",
              "        <script type=\"application/json\" id=\"1157\">\n",
              "          {\"17514e92-17fe-4823-850e-eba15505c5d6\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"1051\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"items\":[{\"id\":\"1054\"},{\"id\":\"1055\"}],\"location\":[0,0]},\"id\":\"1056\",\"type\":\"Legend\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1027\"},{\"id\":\"1028\"},{\"id\":\"1029\"}]},\"id\":\"1031\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1019\"},\"dimension\":1,\"ticker\":null},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"1015\"}],\"center\":[{\"id\":\"1018\"},{\"id\":\"1022\"}],\"left\":[{\"id\":\"1019\"}],\"renderers\":[{\"id\":\"1042\"}],\"right\":[{\"id\":\"1056\"}],\"title\":{\"id\":\"1005\"},\"toolbar\":{\"id\":\"1031\"},\"x_range\":{\"id\":\"1007\"},\"x_scale\":{\"id\":\"1011\"},\"y_range\":{\"id\":\"1009\"},\"y_scale\":{\"id\":\"1013\"}},\"id\":\"1004\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1002\"}},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1002\"}},\"size\":{\"value\":20},\"x\":{\"field\":\"inference_latency\"},\"y\":{\"field\":\"performance\"}},\"id\":\"1041\",\"type\":\"Circle\"},{\"attributes\":{\"data\":{\"hyperparameters\":[\"weights: uniform&lt;br&gt;n_jobs: -1\",\"weights: distance&lt;br&gt;n_jobs: -1\",\"use_orig_features: False&lt;br&gt;max_base_models: 25&lt;br&gt;max_base_models_per_type: 5&lt;br&gt;save_bag_folds: True\"],\"inference_latency\":[0.10903358459472656,0.10753440856933594,0.21730732917785645],\"model\":[\"KNeighborsUnif\",\"KNeighborsDist\",\"WeightedEnsemble_L2\"],\"model_type\":[\"KNNModel\",\"KNNModel\",\"WeightedEnsembleModel\"],\"performance\":[0.5364,0.5568,0.5644],\"training_time\":[0.7413389682769775,0.7609128952026367,1.7800462245941162]},\"selected\":{\"id\":\"1052\"},\"selection_policy\":{\"id\":\"1051\"}},\"id\":\"1003\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"PanTool\"},{\"attributes\":{\"text\":\"Models produced during fit()\"},\"id\":\"1005\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"CrosshairTool\"},{\"attributes\":{\"index\":2,\"label\":{\"value\":\"WeightedEnsembleModel\"},\"renderers\":[{\"id\":\"1042\"}]},\"id\":\"1055\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"1003\"}},\"id\":\"1043\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"inference_latency\",\"formatter\":{\"id\":\"1048\"},\"major_label_policy\":{\"id\":\"1049\"},\"ticker\":{\"id\":\"1016\"}},\"id\":\"1015\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1016\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"performance\",\"@performance{safe}\"],[\"model\",\"@model{safe}\"],[\"model_type\",\"@model_type{safe}\"],[\"hyperparameters\",\"@hyperparameters{safe}\"],[\"inference_latency\",\"@inference_latency{safe}\"],[\"training_time\",\"@training_time{safe}\"]]},\"id\":\"1028\",\"type\":\"HoverTool\"},{\"attributes\":{\"axis\":{\"id\":\"1015\"},\"ticker\":null},\"id\":\"1018\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1052\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"overlay\":{\"id\":\"1030\"}},\"id\":\"1026\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1029\",\"type\":\"SaveTool\"},{\"attributes\":{\"axis_label\":\"performance\",\"formatter\":{\"id\":\"1045\"},\"major_label_policy\":{\"id\":\"1046\"},\"ticker\":{\"id\":\"1020\"}},\"id\":\"1019\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"factors\":[\"KNNModel\",\"WeightedEnsembleModel\"],\"palette\":[\"#1f77b4\",\"#ff7f0e\"]},\"id\":\"1002\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{\"index\":0,\"label\":{\"value\":\"KNNModel\"},\"renderers\":[{\"id\":\"1042\"}]},\"id\":\"1054\",\"type\":\"LegendItem\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1030\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"data_source\":{\"id\":\"1003\"},\"glyph\":{\"id\":\"1040\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1041\"},\"view\":{\"id\":\"1043\"}},\"id\":\"1042\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1027\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"AllLabels\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1002\"}},\"line_alpha\":{\"value\":0.5},\"line_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1002\"}},\"size\":{\"value\":20},\"x\":{\"field\":\"inference_latency\"},\"y\":{\"field\":\"performance\"}},\"id\":\"1040\",\"type\":\"Circle\"}],\"root_ids\":[\"1004\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}}\n",
              "        </script>\n",
              "        <script type=\"text/javascript\">\n",
              "          (function() {\n",
              "            var fn = function() {\n",
              "              Bokeh.safely(function() {\n",
              "                (function(root) {\n",
              "                  function embed_document(root) {\n",
              "                    \n",
              "                  var docs_json = document.getElementById('1157').textContent;\n",
              "                  var render_items = [{\"docid\":\"17514e92-17fe-4823-850e-eba15505c5d6\",\"root_ids\":[\"1004\"],\"roots\":{\"1004\":\"ea73301c-aae6-4183-81a1-0a635e0a6c6e\"}}];\n",
              "                  root.Bokeh.embed.embed_items(docs_json, render_items);\n",
              "                \n",
              "                  }\n",
              "                  if (root.Bokeh !== undefined) {\n",
              "                    embed_document(root);\n",
              "                  } else {\n",
              "                    var attempts = 0;\n",
              "                    var timer = setInterval(function(root) {\n",
              "                      if (root.Bokeh !== undefined) {\n",
              "                        clearInterval(timer);\n",
              "                        embed_document(root);\n",
              "                      } else {\n",
              "                        attempts++;\n",
              "                        if (attempts > 100) {\n",
              "                          clearInterval(timer);\n",
              "                          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "                        }\n",
              "                      }\n",
              "                    }, 10, root)\n",
              "                  }\n",
              "                })(window);\n",
              "              });\n",
              "            };\n",
              "            if (document.readyState != \"loading\") fn();\n",
              "            else document.addEventListener(\"DOMContentLoaded\", fn);\n",
              "          })();\n",
              "        </script>\n",
              "    \n",
              "  </body>\n",
              "  \n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a66563",
      "metadata": {
        "id": "a0a66563"
      },
      "source": [
        "### パス指定していたが何していた？！\n",
        "\n",
        "→ディスクの中身見てみよう！！"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "624d3c1b",
      "metadata": {
        "id": "624d3c1b"
      },
      "source": [
        "AutoGluonによる前処理済みの学習データ\n",
        "\n",
        "目的変数込みで20カラムから2040カラムまで増加"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21afa83",
      "metadata": {
        "scrolled": true,
        "id": "c21afa83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "8f958d67-ff63-4cfc-a87d-a6087b512b49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a940224f-890c-4b34-9cb2-bc1da3b5d318\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>biggenre</th>\n",
              "      <th>genre</th>\n",
              "      <th>novel_type</th>\n",
              "      <th>isr15</th>\n",
              "      <th>isbl</th>\n",
              "      <th>isgl</th>\n",
              "      <th>iszankoku</th>\n",
              "      <th>istensei</th>\n",
              "      <th>istenni</th>\n",
              "      <th>pc_or_k</th>\n",
              "      <th>title</th>\n",
              "      <th>story</th>\n",
              "      <th>keyword</th>\n",
              "      <th>writer</th>\n",
              "      <th>general_firstup</th>\n",
              "      <th>story.char_count</th>\n",
              "      <th>story.word_count</th>\n",
              "      <th>story.capital_ratio</th>\n",
              "      <th>story.lower_ratio</th>\n",
              "      <th>story.digit_ratio</th>\n",
              "      <th>story.special_ratio</th>\n",
              "      <th>story.symbol_count.!</th>\n",
              "      <th>story.symbol_ratio.!</th>\n",
              "      <th>story.symbol_count.?</th>\n",
              "      <th>story.symbol_ratio.?</th>\n",
              "      <th>story.symbol_count.&amp;</th>\n",
              "      <th>story.symbol_ratio.&amp;</th>\n",
              "      <th>story.symbol_count..</th>\n",
              "      <th>story.symbol_ratio..</th>\n",
              "      <th>story.symbol_count.:</th>\n",
              "      <th>story.symbol_ratio.:</th>\n",
              "      <th>story.symbol_count.</th>\n",
              "      <th>story.symbol_ratio.</th>\n",
              "      <th>story.symbol_count./</th>\n",
              "      <th>story.symbol_ratio./</th>\n",
              "      <th>story.symbol_count.;</th>\n",
              "      <th>story.symbol_ratio.;</th>\n",
              "      <th>story.symbol_count.-</th>\n",
              "      <th>story.symbol_ratio.-</th>\n",
              "      <th>...</th>\n",
              "      <th>__nlp__.青春 異能力バトル</th>\n",
              "      <th>__nlp__.青春 異能力バトル ヒーロー</th>\n",
              "      <th>__nlp__.青春 異能力バトル ラブコメ</th>\n",
              "      <th>__nlp__.青春 異能力バトル 冒険</th>\n",
              "      <th>__nlp__.青春 百合</th>\n",
              "      <th>__nlp__.青春 私小説</th>\n",
              "      <th>__nlp__.青春 私小説 ホームドラマ</th>\n",
              "      <th>__nlp__.青春 近未来</th>\n",
              "      <th>__nlp__.非テンプレ</th>\n",
              "      <th>__nlp__.非デスゲーム</th>\n",
              "      <th>__nlp__.非日常</th>\n",
              "      <th>__nlp__.音楽</th>\n",
              "      <th>__nlp__.願い</th>\n",
              "      <th>__nlp__.食事</th>\n",
              "      <th>__nlp__.飯テロ</th>\n",
              "      <th>__nlp__.騎士</th>\n",
              "      <th>__nlp__.高校</th>\n",
              "      <th>__nlp__.高校生</th>\n",
              "      <th>__nlp__.魔女</th>\n",
              "      <th>__nlp__.魔族</th>\n",
              "      <th>__nlp__.魔法</th>\n",
              "      <th>__nlp__.魔法 ゲーム</th>\n",
              "      <th>__nlp__.魔法 ダンジョン</th>\n",
              "      <th>__nlp__.魔法 チート</th>\n",
              "      <th>__nlp__.魔法 ハッピーエンド</th>\n",
              "      <th>__nlp__.魔法 ファンタジー</th>\n",
              "      <th>__nlp__.魔法 異世界</th>\n",
              "      <th>__nlp__.魔法 超能力</th>\n",
              "      <th>__nlp__.魔法使い</th>\n",
              "      <th>__nlp__.魔法少女</th>\n",
              "      <th>__nlp__.魔物</th>\n",
              "      <th>__nlp__.魔王</th>\n",
              "      <th>__nlp__.魔王 勇者</th>\n",
              "      <th>__nlp__.魔術</th>\n",
              "      <th>__nlp__.魔術師</th>\n",
              "      <th>__nlp__.黒森</th>\n",
              "      <th>__nlp__.ａｉ</th>\n",
              "      <th>__nlp__.ｓｆ</th>\n",
              "      <th>__nlp__.ｖｒｍｍｏ</th>\n",
              "      <th>__nlp__._total_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32141</th>\n",
              "      <td>12136</td>\n",
              "      <td>3</td>\n",
              "      <td>302</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4019</td>\n",
              "      <td>1625497235000000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29349</th>\n",
              "      <td>1635704</td>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5056</td>\n",
              "      <td>1624222548000000000</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39826</th>\n",
              "      <td>1371754</td>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1628664115000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11589</th>\n",
              "      <td>728483</td>\n",
              "      <td>4</td>\n",
              "      <td>402</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5042</td>\n",
              "      <td>1580554800000000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20473</th>\n",
              "      <td>2034554</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1808</td>\n",
              "      <td>1615447312000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6466</th>\n",
              "      <td>1294746</td>\n",
              "      <td>4</td>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1533424904000000000</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16969</th>\n",
              "      <td>1054237</td>\n",
              "      <td>99</td>\n",
              "      <td>9901</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130</td>\n",
              "      <td>1608164231000000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32744</th>\n",
              "      <td>1384436</td>\n",
              "      <td>3</td>\n",
              "      <td>302</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>144</td>\n",
              "      <td>1625738400000000000</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15845</th>\n",
              "      <td>2039783</td>\n",
              "      <td>4</td>\n",
              "      <td>403</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1603745119000000000</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38945</th>\n",
              "      <td>1093897</td>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1628298507000000000</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37500 rows × 2040 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a940224f-890c-4b34-9cb2-bc1da3b5d318')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a940224f-890c-4b34-9cb2-bc1da3b5d318 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a940224f-890c-4b34-9cb2-bc1da3b5d318');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        userid  biggenre  genre  ...  __nlp__.ｓｆ  __nlp__.ｖｒｍｍｏ  __nlp__._total_\n",
              "32141    12136         3    302  ...           0              0               16\n",
              "29349  1635704         1    102  ...           0              0               15\n",
              "39826  1371754         2    201  ...           0              0                1\n",
              "11589   728483         4    402  ...           0              0                8\n",
              "20473  2034554         3    301  ...           0              0                0\n",
              "...        ...       ...    ...  ...         ...            ...              ...\n",
              "6466   1294746         4    401  ...           0              0                9\n",
              "16969  1054237        99   9901  ...           0              0                9\n",
              "32744  1384436         3    302  ...           0              0                9\n",
              "15845  2039783         4    403  ...           0              0               15\n",
              "38945  1093897         2    201  ...           0              0               13\n",
              "\n",
              "[37500 rows x 2040 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X = pd.read_pickle(f'{save_path}/utils/data/X.pkl')\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6c0d81",
      "metadata": {
        "id": "2a6c0d81"
      },
      "source": [
        "カラムの一覧"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a0a199",
      "metadata": {
        "id": "d1a0a199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2e2a2d-b5a3-4cab-ee9c-8d457c3560a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['userid', 'biggenre', 'genre', 'novel_type', 'isr15', 'isbl', 'isgl',\n",
              "       'iszankoku', 'istensei', 'istenni',\n",
              "       ...\n",
              "       '__nlp__.魔物', '__nlp__.魔王', '__nlp__.魔王 勇者', '__nlp__.魔術',\n",
              "       '__nlp__.魔術師', '__nlp__.黒森', '__nlp__.ａｉ', '__nlp__.ｓｆ',\n",
              "       '__nlp__.ｖｒｍｍｏ', '__nlp__._total_'],\n",
              "      dtype='object', length=2040)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c68252",
      "metadata": {
        "id": "b0c68252"
      },
      "source": [
        "nlp____:CountVectorizerを用いてあらすじとキーワードの頻出単語のカウントを行っている\n",
        "\n",
        "カテゴリカル変数と文章が前処理されこのように特徴量として使われていた"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 効率化編\n"
      ],
      "metadata": {
        "id": "sGiaunqvDQSX"
      },
      "id": "sGiaunqvDQSX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## リリース時の効率化\n",
        "リリース時に学習を効率化させる目的での機能も追加されている\n",
        "\n",
        "* モデルの重みの変更\n",
        "    * 重みにL2ノルムをかけることで、不要なパラメータを減らす。追加学習する必要がなく、より少ないモデルの重み付き和で同等の出力を得ようとすることで、推論を軽量化できる。\n",
        "    * `redictor.fit_weighted_ensemble(expand_pareto_frontier=True)`で実行できる\n",
        "* refit\n",
        "    * バギングを使って学習しているものに関して、シングルモデル化することによってファイルの容量を減らしたり、推論の高速化をみこむ（精度は下がる）\n",
        "* Model distillation\n",
        "    * アンサンブルされているそれぞれのモデルは、アンサンブルした結果のモデルに対して性能劣化がある。そのためアンサンブルした結果の数値を目標値としてそれぞれのモデルを再度学習させることで、アンサンブルの結果を生かしつつ、シングルモデルの利点も活かしたモデルが得られる。\n",
        "    * `predictor.distill()`で実行できる\n",
        "\n"
      ],
      "metadata": {
        "id": "Kms-EIF3wwEp"
      },
      "id": "Kms-EIF3wwEp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習時の効率化\n",
        "\n"
      ],
      "metadata": {
        "id": "vgfMDJZbwvfR"
      },
      "id": "vgfMDJZbwvfR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### presetsの設定\n",
        "\n",
        "プリセットの設定をすることで上記のrefitやハイパーパラメータの軽量化など様々な設定を一度に行うことができる。一番最初は細々としたパラメータを変更するのではなくて、このプリセットの設定から入ることが推奨されている。\n",
        "\n",
        "* `best_quality={'auto_stack': True}`\n",
        "    * 最も性能がいいもの。長い学習時間を許容できるのであればこの設定でやりたい。\n",
        "* `high_quality_fast_inference_only_refit={'auto_stack': True, 'refit_full': True, 'set_best_to_refit_full': True, '_save_bag_folds': False}`\n",
        "    * refitをかけることによってbest_qualityに対して10xから200xの推論高速化と小容量化が期待できる。モデルサイズが小さい方がいい場合に指定すると良い。\n",
        "* `good_quality_faster_inference_only_refit={'auto_stack': True, 'refit_full': True, 'set_best_to_refit_full': True, '_save_bag_folds': False, 'hyperparameters': 'light'}`\n",
        "    * high_quality_fast_inference_only_refitに対して4倍程度の推論高速化と小容量化が期待できる。高速低容量が要求される場合に推奨される。\n",
        "* `medium_quality_faster_train={'auto_stack': False}`\n",
        "    * good_quality_faster_inference_only_refitの20倍推論が早い。**AutoGluonのデフォルト設定**。\n",
        "* `optimize_for_deployment={'keep_only_best': True, 'save_space': True}`\n",
        "    * 推論速度の低下などは無いが、学習に必要としないモデルを削除するため、2から4倍のディスク容量の削減になる\n",
        "* `ignore_text={'_feature_generator_kwargs': {'enable_text_ngram_features': False, 'enable_text_special_features': False, 'enable_raw_text_features': False}}`\n",
        "    * テキストが検出された場合にテキストを利用した特徴量の作成を行うが、その機能を使わなくする。文章情報がどれだけ結果に寄与しているのかどうかを確認するためにも役に立つ。"
      ],
      "metadata": {
        "id": "FoFfSsOrxH_m"
      },
      "id": "FoFfSsOrxH_m"
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_light = (\n",
        "    TabularPredictor(\n",
        "        label=label, \n",
        "        eval_metric=metric\n",
        "    ).fit(\n",
        "        train_df, \n",
        "        presets='good_quality_faster_inference_only_refit', \n",
        "        time_limit=60\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7jViqctxLsP",
        "outputId": "9b2c8877-345e-48f7-8300-9fad6708cb71"
      },
      "id": "o7jViqctxLsP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220204_002220/\"\n",
            "Presets specified: ['good_quality_faster_inference_only_refit']\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220204_002220/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    40000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [1, 2, 3, 0, 4]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11176.32 MB\n",
            "\tTrain Data (Original)  Memory Usage: 59.55 MB (0.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1991\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 1991 to 643 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :   2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :   2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :   4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :  32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :   7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :   1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 644 | ['__nlp__.123大賞', '__nlp__.2020', '__nlp__.2021', '__nlp__.ai', '__nlp__.amp', ...]\n",
            "\t21.8s = Fit runtime\n",
            "\t16 features in original data used to generate 692 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 55.0 MB (0.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 22.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 25.19s of the 37.78s of remaining time.\n",
            "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 18.18s of the 30.77s of remaining time.\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 4. Best iteration is:\n",
            "\t[4]\ttrain_set's multi_logloss: 1.08536\tvalid_set's multi_logloss: 1.09541\n",
            "\tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15.74s of the 28.33s of remaining time.\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\t[1]\ttrain_set's multi_logloss: 1.14298\tvalid_set's multi_logloss: 1.14694\n",
            "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 13.45s of the 26.04s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 156 due to low time. Expected time usage reduced from 25.5s -> 13.5s...\n",
            "\t-0.9223\t = Validation score   (log_loss)\n",
            "\t12.32s\t = Training   runtime\n",
            "\t7.19s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 37.79s of the 5.96s of remaining time.\n",
            "\t-0.9223\t = Validation score   (log_loss)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting 11 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 5.91s of the 5.86s of remaining time.\n",
            "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "No base models to train on, skipping weighted ensemble...\n",
            "AutoGluon training complete, total runtime = 61.67s ...\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL ...\n",
            "\t-0.9223\t = Validation score   (log_loss)\n",
            "\t14.95s\t = Training   runtime\n",
            "\t7.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL ...\n",
            "\t-0.9223\t = Validation score   (log_loss)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220204_002220/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparametersの設定\n",
        "\n",
        "strまたはdictで与える引数で、学習時のモデルのハイパーパラメータ設定を行う。設定値は`['default', 'light', 'very_light', 'toy', 'multimodal'`の5つで`'multimodal'`以外は左から順番に学習時間が短くなり、精度も悪化する。モデルのプロトタイピングには使用できるが、プロダクションでは使えない。\n"
      ],
      "metadata": {
        "id": "e8ToMcY2w41Y"
      },
      "id": "e8ToMcY2w41Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# 軽量なモデルの学習を行うこともできる。結果学習も早くなる。\n",
        "predictor_light = (\n",
        "    TabularPredictor(\n",
        "        label=label, \n",
        "        eval_metric=metric\n",
        "    ).fit(\n",
        "        train_df, \n",
        "        hyperparameters='very_light', \n",
        "        time_limit=60\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL-HE2LJxCw6",
        "outputId": "04b6173f-dcb2-49a9-a7cc-946f54af6c83"
      },
      "id": "mL-HE2LJxCw6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220204_002345/\"\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220204_002345/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    40000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [1, 2, 3, 0, 4]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11339.05 MB\n",
            "\tTrain Data (Original)  Memory Usage: 59.55 MB (0.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1991\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 1991 to 649 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :   2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :   2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :   4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :  32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :   7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :   1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 650 | ['__nlp__.123大賞', '__nlp__.2020', '__nlp__.2021', '__nlp__.ai', '__nlp__.amp', ...]\n",
            "\t19.2s = Fit runtime\n",
            "\t16 features in original data used to generate 698 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 55.48 MB (0.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 19.56s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.0625, Train Rows: 37500, Val Rows: 2500\n",
            "Fitting 6 L1 models ...\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 40.44s of the 40.43s of remaining time.\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
            "\t-0.8151\t = Validation score   (log_loss)\n",
            "\t39.48s\t = Training   runtime\n",
            "\t0.58s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 0.26s of the 0.25s of remaining time.\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\t[1]\ttrain_set's multi_logloss: 1.14395\tvalid_set's multi_logloss: 1.14837\n",
            "\t-1.1484\t = Validation score   (log_loss)\n",
            "\t1.75s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 40.44s of the -2.23s of remaining time.\n",
            "\t-0.8002\t = Validation score   (log_loss)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 63.14s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220204_002345/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの除外\n",
        "\n",
        "学習するモデルの除外を行うこともできる。特に学習に時間がかかるけど精度にあまり影響がないKNNモデルなどを除外した場合に学習時間に対する精度の向上が見込まれる。"
      ],
      "metadata": {
        "id": "xcUhN2oKw9sM"
      },
      "id": "xcUhN2oKw9sM"
    },
    {
      "cell_type": "code",
      "source": [
        "excluded_model_types = ['KNN', 'NN']  # 除外したいモデルの指定\n",
        "predictor_light = (\n",
        "    TabularPredictor(\n",
        "        label=label, \n",
        "        eval_metric=metric\n",
        "    ).fit(\n",
        "        train_df, \n",
        "        excluded_model_types=excluded_model_types, \n",
        "        time_limit=60\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0bOJaMejrJV",
        "outputId": "c72aa9a5-373a-492d-d069-aca586d95605"
      },
      "id": "D0bOJaMejrJV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220204_002448/\"\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220204_002448/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    40000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [1, 2, 3, 0, 4]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11193.27 MB\n",
            "\tTrain Data (Original)  Memory Usage: 59.55 MB (0.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1991\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 1991 to 582 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :   2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :   2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :   4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :  32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :   7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :   1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 583 | ['__nlp__.123大賞', '__nlp__.2021', '__nlp__.ai', '__nlp__.amp', '__nlp__.bl', ...]\n",
            "\t22.8s = Fit runtime\n",
            "\t16 features in original data used to generate 631 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 50.12 MB (0.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 23.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.0625, Train Rows: 37500, Val Rows: 2500\n",
            "Excluded Model Types: ['KNN', 'NN']\n",
            "\tFound 'NN' model in hyperparameters, but 'NN' is present in `excluded_model_types` and will be removed.\n",
            "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
            "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
            "Fitting 10 L1 models ...\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 36.81s of the 36.79s of remaining time.\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "\t-0.8162\t = Validation score   (log_loss)\n",
            "\t35.75s\t = Training   runtime\n",
            "\t0.45s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 0.5s of the 0.48s of remaining time.\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\t[1]\ttrain_set's multi_logloss: 1.1527\tvalid_set's multi_logloss: 1.15632\n",
            "\t-1.1563\t = Validation score   (log_loss)\n",
            "\t1.68s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 36.81s of the -1.86s of remaining time.\n",
            "\t-0.8013\t = Validation score   (log_loss)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 62.71s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220204_002448/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパパラメタ最適化（Hyper Parameter Optimization; HPO）編\n",
        "\n",
        "autogluonでもハイパパラメタの探索はできる。効率的にパラメタを探しながら、どのモデルがいいかを調べることができる"
      ],
      "metadata": {
        "id": "V8RoyT_-rbz3"
      },
      "id": "V8RoyT_-rbz3"
    },
    {
      "cell_type": "code",
      "source": [
        "time_limit = 60  # モデルを1分ぐらい学習させる\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_df, \n",
        "    time_limit=time_limit,\n",
        "    hyperparameter_tune_kwargs=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHjWUg9hrbhe",
        "outputId": "fad83c33-79ff-485e-a4c9-054e3a2aad47"
      },
      "id": "wHjWUg9hrbhe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220204_002551/\"\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220204_002551/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    40000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [1, 2, 3, 0, 4]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11113.98 MB\n",
            "\tTrain Data (Original)  Memory Usage: 59.55 MB (0.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1991\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 1991 to 580 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :   2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :   2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :   4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :  32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :   7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :   1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 581 | ['__nlp__.123大賞', '__nlp__.2021', '__nlp__.ai', '__nlp__.amp', '__nlp__.bl', ...]\n",
            "\t18.9s = Fit runtime\n",
            "\t16 features in original data used to generate 629 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 49.96 MB (0.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 19.24s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.125, Train Rows: 35000, Val Rows: 5000\n",
            "Fitting 13 L1 models ...\n",
            "Hyperparameter tuning model: KNeighborsUnif ...\n",
            "Fitted model: KNeighborsUnif ...\n",
            "\t-2.866\t = Validation score   (log_loss)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Hyperparameter tuning model: KNeighborsDist ...\n",
            "Fitted model: KNeighborsDist ...\n",
            "\t-3.6002\t = Validation score   (log_loss)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI ...\n",
            "Warning: Exception caused NeuralNetFastAI to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 1155, in _train_single_full\n",
            "    hpo_models, hpo_model_performances, hpo_results = model.hyperparameter_tune(X=X, y=y, X_val=X_val, y_val=y_val, scheduler_options=hyperparameter_tune_kwargs, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 830, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(scheduler_options=scheduler_options, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 394, in _hyperparameter_tune\n",
            "    return skip_hpo(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 98, in skip_hpo\n",
            "    fit_and_save_model(model=model, params=dict(), fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 248, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: LightGBMXT ...\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 34. Best iteration is:\n",
            "\t[34]\ttrain_set's multi_logloss: 0.857779\tvalid_set's multi_logloss: 0.904797\n",
            "\tTime limit exceeded\n",
            "Fitted model: LightGBMXT/T0 ...\n",
            "\t-0.9048\t = Validation score   (log_loss)\n",
            "\t2.07s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM ...\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 30. Best iteration is:\n",
            "\t[30]\ttrain_set's multi_logloss: 0.811059\tvalid_set's multi_logloss: 0.873195\n",
            "\tTime limit exceeded\n",
            "Fitted model: LightGBM/T0 ...\n",
            "\t-0.8732\t = Validation score   (log_loss)\n",
            "\t2.06s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForestGini ...\n",
            "\tWarning: Model is expected to require 62.6s to train, which exceeds the maximum time limit of 2.8s, skipping model...\n",
            "Warning: Exception caused RandomForestGini to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 1155, in _train_single_full\n",
            "    hpo_models, hpo_model_performances, hpo_results = model.hyperparameter_tune(X=X, y=y, X_val=X_val, y_val=y_val, scheduler_options=hyperparameter_tune_kwargs, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 830, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(scheduler_options=scheduler_options, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 282, in _hyperparameter_tune\n",
            "    return skip_hpo(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 98, in skip_hpo\n",
            "    fit_and_save_model(model=model, params=dict(), fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 179, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: RandomForestEntr ...\n",
            "\tWarning: Model is expected to require 62.5s to train, which exceeds the maximum time limit of 2.8s, skipping model...\n",
            "Warning: Exception caused RandomForestEntr to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 1155, in _train_single_full\n",
            "    hpo_models, hpo_model_performances, hpo_results = model.hyperparameter_tune(X=X, y=y, X_val=X_val, y_val=y_val, scheduler_options=hyperparameter_tune_kwargs, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 830, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(scheduler_options=scheduler_options, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 282, in _hyperparameter_tune\n",
            "    return skip_hpo(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 98, in skip_hpo\n",
            "    fit_and_save_model(model=model, params=dict(), fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 179, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: CatBoost ...\n",
            "\tTime limit exceeded\n",
            "Fitted model: CatBoost/T0 ...\n",
            "\t-1.1834\t = Validation score   (log_loss)\n",
            "\t4.99s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Hyperparameter tuning model: ExtraTreesGini ...\n",
            "\tWarning: Model is expected to require 62.7s to train, which exceeds the maximum time limit of 2.8s, skipping model...\n",
            "Warning: Exception caused ExtraTreesGini to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 1155, in _train_single_full\n",
            "    hpo_models, hpo_model_performances, hpo_results = model.hyperparameter_tune(X=X, y=y, X_val=X_val, y_val=y_val, scheduler_options=hyperparameter_tune_kwargs, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 830, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(scheduler_options=scheduler_options, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 282, in _hyperparameter_tune\n",
            "    return skip_hpo(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 98, in skip_hpo\n",
            "    fit_and_save_model(model=model, params=dict(), fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 179, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: ExtraTreesEntr ...\n",
            "\tWarning: Model is expected to require 62.6s to train, which exceeds the maximum time limit of 2.8s, skipping model...\n",
            "Warning: Exception caused ExtraTreesEntr to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 1155, in _train_single_full\n",
            "    hpo_models, hpo_model_performances, hpo_results = model.hyperparameter_tune(X=X, y=y, X_val=X_val, y_val=y_val, scheduler_options=hyperparameter_tune_kwargs, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 830, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(scheduler_options=scheduler_options, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 282, in _hyperparameter_tune\n",
            "    return skip_hpo(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 98, in skip_hpo\n",
            "    fit_and_save_model(model=model, params=dict(), fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 179, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: XGBoost ...\n",
            "\tTime limit exceeded\n",
            "Fitted model: XGBoost/T0 ...\n",
            "\t-0.988\t = Validation score   (log_loss)\n",
            "\t2.84s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet ...\n",
            "\tTime limit exceeded\n",
            "Fitting model: LightGBMLarge ... Training model for up to 2.82s of the 5.14s of remaining time.\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 15. Best iteration is:\n",
            "\t[15]\ttrain_set's multi_logloss: 0.905753\tvalid_set's multi_logloss: 0.982393\n",
            "\t-0.9824\t = Validation score   (log_loss)\n",
            "\t3.2s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 40.76s of the 0.93s of remaining time.\n",
            "\t-0.8536\t = Validation score   (log_loss)\n",
            "\t2.16s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 61.56s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220204_002551/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = predictor.fit_summary(show_plot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-5f1BGYsCt4",
        "outputId": "7b879791-bd8c-4364-d527-1e4778e56b3a"
      },
      "id": "h-5f1BGYsCt4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L2  -0.853620       0.315077  4.317303                0.002443           2.163424            2       True          8\n",
            "1          LightGBM/T0  -0.873195       0.096112  2.056905                0.096112           2.056905            1       True          4\n",
            "2        LightGBMXT/T0  -0.904797       0.109620  2.074088                0.109620           2.074088            1       True          3\n",
            "3        LightGBMLarge  -0.982393       0.092580  3.202636                0.092580           3.202636            1       True          7\n",
            "4           XGBoost/T0  -0.987972       0.084637  2.836012                0.084637           2.836012            1       True          6\n",
            "5          CatBoost/T0  -1.183438       0.073960  4.985294                0.073960           4.985294            1       True          5\n",
            "6       KNeighborsUnif  -2.865992       0.215108  0.102505                0.215108           0.102505            1       True          1\n",
            "7       KNeighborsDist  -3.600169       0.216523  0.096974                0.216523           0.096974            1       True          2\n",
            "Number of models trained: 8\n",
            "Types of models trained:\n",
            "{'CatBoostModel', 'LGBModel', 'XGBoostModel', 'KNNModel', 'WeightedEnsembleModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])                    :   2 | ['title', 'writer']\n",
            "('category', ['text_as_category'])  :   2 | ['story', 'keyword']\n",
            "('int', [])                         :   4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "('int', ['binned', 'text_special']) :  32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "('int', ['bool'])                   :   7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "('int', ['datetime_as_int'])        :   1 | ['general_firstup']\n",
            "('int', ['text_ngram'])             : 581 | ['__nlp__.123大賞', '__nlp__.2021', '__nlp__.ai', '__nlp__.amp', '__nlp__.bl', ...]\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20220204_002551/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 詳細なパラメータ探索\n",
        "\n",
        "パラメータ探索よりモデルのアンサンブルに時間をかける方がAutoGluonの思想には合っているが、適切なハイパパラメタ設定が学習設定に影響を与えることはあるので、詳細に設定する方法も用意されている。ただ、それぞれのモデルのパラメータを参照する場合はモデルが利用しているライブラリまで参照する必要があるため、ちょっと大変。\n",
        "\n",
        "\n",
        "> 参考: [モデルの設定パラメータ一覧](https://auto.gluon.ai/stable/api/autogluon.predictor.html#:~:text=Details%20regarding%20the%20hyperparameters%20you%20can%20specify%20for%20each%20model%20are%20provided%20in%20the%20following%20files%3A)\n",
        "\n",
        "\n",
        "また、以下のモデルではハイパーパラメータ探索は無効となっている\n",
        "\n",
        "*   ランダムフォレスト(RF)\n",
        "*   Extremely Randomized Trees(XT)\n",
        "*   K近傍法(KNN)\n",
        "*   ロジスティック回帰(LR)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-4YlZjfCrUZ-"
      },
      "id": "-4YlZjfCrUZ-"
    },
    {
      "cell_type": "code",
      "source": [
        "import autogluon.core as ag\n",
        "nn_options = {  # NNのデフォルトではないパラメータを設定する\n",
        "    'num_epochs': 10,  # 学習のエポック数（これによって学習時間の長さが決まる）\n",
        "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # 対数スケールで学習率を探索\n",
        "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # NNを学習するときの活性化関数の指定\n",
        "    'layers': ag.space.Categorical([100], [1000], [200, 100], [300, 200, 100]),  # NNレイヤ数とユニット数の設定\n",
        "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # ドロップアウトの確率\n",
        "}\n",
        "\n",
        "gbm_options = {  # LightGBMのパラメタの指定\n",
        "    'num_boost_round': 100,  # ブースティングの回数\n",
        "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # 木の葉の数\n",
        "}\n",
        "\n",
        "hyperparameters = {  # それぞれのモデルのハイパーパラメータ                  \n",
        "    'GBM': gbm_options,\n",
        "    'NN': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
        "}  # 注:キーがない場合にはそのモデルは学習されない\n",
        "\n",
        "time_limit = 60  # モデルを1分ぐらい学習させる\n",
        "num_trials = 30  # 最大でも一つのモデルに対して30試行\n",
        "search_strategy = 'auto'  # ベイス最適化を利用したパラメータ探索は\"auto\"に設定する\n",
        "\n",
        "hyperparameter_tune_kwargs = {  # HPOはこの変数が定義されない限りは実行されない\n",
        "    'num_trials': num_trials,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher': search_strategy,\n",
        "}\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_df, \n",
        "    time_limit=time_limit,\n",
        "    hyperparameters=hyperparameters, \n",
        "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bedd2a8195cd453b8fe3d9225b7ccf5d",
            "1ba30fda63404defb67f7044b7ad3f7d",
            "9b9964204895497ebf1ec4c89f860190",
            "0aff0a95f2ba425f8afa97b92eeb3949",
            "834076516b4d4506aa78af563ecb97d1",
            "26e7d192ede54bd39e66bc105014c307",
            "ef4ab6f193ac4e9fa76fe2b976865a81",
            "5afeea8fdac94c2cacc9e5b4df0eb49f",
            "968f3075b3a94eed9841e826d4069090",
            "f7e4704d29514a87b3a208446384954c",
            "4de816cba798428590c7b4d4a2da29a6",
            "e9ff3ecbd7a04381bb343dce896b1e1c",
            "515feec3b9b948d88af2ca588496e522",
            "b0a7ec5be4514fc09ef93dceaaa4c4bc",
            "52520fba8ef7443d87c1034ff64ef6da",
            "37ccbd298f5643408b281ec034746f36",
            "7745f060736b4ef5992a464d7a4c1dd2",
            "db6d3bab50774c1d818ef091d9aa644c",
            "1675b1ccc1e84ee9a18eec88ae84ecc2",
            "f018f5d1248c413f8bb75c9c0ddc6112",
            "61aadf5642d24e45bb65bcfe6000f21b",
            "21d55374ea8d457487960cad7bc1b101"
          ]
        },
        "id": "6AUiXtd2h-LC",
        "outputId": "a11e81bf-55e9-4423-f722-fd26a802c605"
      },
      "id": "6AUiXtd2h-LC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220204_002653/\"\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220204_002653/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    40000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [1, 2, 3, 0, 4]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10986.35 MB\n",
            "\tTrain Data (Original)  Memory Usage: 59.55 MB (0.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1991\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 1991 to 545 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :   2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :   2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :   4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :  32 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :   7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :   1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 546 | ['__nlp__.123大賞', '__nlp__.2021', '__nlp__.ai', '__nlp__.amp', '__nlp__.com', ...]\n",
            "\t19.4s = Fit runtime\n",
            "\t16 features in original data used to generate 594 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 47.16 MB (0.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 19.74s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.125, Train Rows: 35000, Val Rows: 5000\n",
            "Fitting 2 L1 models ...\n",
            "Hyperparameter tuning model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bedd2a8195cd453b8fe3d9225b7ccf5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tTime limit exceeded\n",
            "Fitted model: LightGBM/T0 ...\n",
            "\t-0.8042\t = Validation score   (log_loss)\n",
            "\t6.06s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitted model: LightGBM/T1 ...\n",
            "\t-0.8731\t = Validation score   (log_loss)\n",
            "\t6.67s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9ff3ecbd7a04381bb343dce896b1e1c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
            "\tTime limit exceeded\n",
            "Fitted model: NeuralNetMXNet/T0 ...\n",
            "\t-0.8995\t = Validation score   (log_loss)\n",
            "\t12.61s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 40.26s of the 8.17s of remaining time.\n",
            "\t-0.8032\t = Validation score   (log_loss)\n",
            "\t1.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 53.23s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220204_002653/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 設定値を変化させて学習させてみよう！"
      ],
      "metadata": {
        "id": "XhyEA6cxkvgH"
      },
      "id": "XhyEA6cxkvgH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "もしランタイムが切れたら以下のコメントアウトを外してここから実行してください！"
      ],
      "metadata": {
        "id": "hUClYxuoKImz"
      },
      "id": "hUClYxuoKImz"
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget -O train.csv https://drive.google.com/uc?id=1bJjDaEjRkQpUX_wFMdkAYjU1kDXDlO3m\n",
        "# ! python3 -m pip install -U pip\n",
        "# ! python3 -m pip install -U setuptools wheel\n",
        "# ! python3 -m pip install -U \"mxnet_cu101<2.0.0\"\n",
        "# ! python3 -m pip install autogluon bokeh\n",
        "# from autogluon.tabular import TabularPredictor, TabularDataset\n",
        "# import pandas as pd\n",
        "# train_df = TabularDataset('train.csv')\n",
        "# label = 'fav_novel_cnt_bin'\n",
        "# metric = 'log_loss'"
      ],
      "metadata": {
        "id": "ctXEfv6PKOJo"
      },
      "id": "ctXEfv6PKOJo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 適用したいプリセット\n",
        "presets = (\n",
        "    # 'best_quality'\n",
        "    # 'high_quality_fast_inference_only_refit'\n",
        "    # 'good_quality_faster_inference_only_refit'\n",
        "    'medium_quality_faster_train'\n",
        "    # 'optimize_for_deployment'\n",
        "    # 'ignore_text'\n",
        ")\n",
        "\n",
        "# 除外したいモデルの指定\n",
        "excluded_model_types = [\n",
        "    # 'GBM', # (LightGBM) \n",
        "    # 'CAT', # (CatBoost) \n",
        "    # 'XGB', # (XGBoost) \n",
        "    # 'RF', # (random forest) \n",
        "    # 'XT', # (extremely randomized trees) \n",
        "    # 'KNN', # (k-nearest neighbors) \n",
        "    # 'LR', # (linear regression) \n",
        "    # 'NN', # (neural network with MXNet backend) \n",
        "    # 'FASTAI', # (neural network with FastAI backend)\n",
        "]  \n",
        "\n",
        "hyperparameters=(\n",
        "    'default'\n",
        "    # 'light'\n",
        "    # 'very_light'\n",
        "    # 'toy' \n",
        "    # 'multimodal'\n",
        ")\n",
        "\n",
        "time_limit = 600 # 最大10分間学習させる\n",
        "predictor = (\n",
        "    TabularPredictor(\n",
        "        label=label, \n",
        "        eval_metric=metric,\n",
        "        path='ws_run_result'\n",
        "    ).fit(\n",
        "        train_df, \n",
        "        presets=presets,\n",
        "        excluded_model_types=excluded_model_types, \n",
        "        hyperparameters=hyperparameters,\n",
        "        time_limit=time_limit\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDg1GVojkvTs",
        "outputId": "471ee9eb-a93b-4649-f2a2-9f782ae5d3c9"
      },
      "id": "hDg1GVojkvTs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ws_run_result\"\n",
            "Presets specified: ['medium_quality_faster_train']\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"ws_run_result/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    32000\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t5 unique label values:  [0, 1, 2, 4, 3]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11614.08 MB\n",
            "\tTrain Data (Original)  Memory Usage: 30.07 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['story', 'keyword']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 1601\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['end', 'isstop']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 1): ['ncode']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 1 | ['ncode']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])                        : 11 | ['userid', 'biggenre', 'genre', 'novel_type', 'isr15', ...]\n",
            "\t\t('object', [])                     :  2 | ['title', 'writer']\n",
            "\t\t('object', ['datetime_as_object']) :  1 | ['general_firstup']\n",
            "\t\t('object', ['text'])               :  2 | ['story', 'keyword']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :    2 | ['title', 'writer']\n",
            "\t\t('category', ['text_as_category'])  :    2 | ['story', 'keyword']\n",
            "\t\t('int', [])                         :    4 | ['userid', 'biggenre', 'genre', 'pc_or_k']\n",
            "\t\t('int', ['binned', 'text_special']) :   28 | ['story.char_count', 'story.word_count', 'story.capital_ratio', 'story.lower_ratio', 'story.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :    7 | ['novel_type', 'isr15', 'isbl', 'isgl', 'iszankoku', ...]\n",
            "\t\t('int', ['datetime_as_int'])        :    1 | ['general_firstup']\n",
            "\t\t('int', ['text_ngram'])             : 1602 | ['__nlp__.01', '__nlp__.06', '__nlp__.07', '__nlp__.08', '__nlp__.10', ...]\n",
            "\t16.3s = Fit runtime\n",
            "\t16 features in original data used to generate 1646 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 105.19 MB (0.9% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 16.95s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.078125, Train Rows: 29500, Val Rows: 2500\n",
            "Excluded Model Types: []\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ... Training model for up to 43.05s of the 43.02s of remaining time.\n",
            "\t-2.909\t = Validation score   (log_loss)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ... Training model for up to 42.73s of the 42.7s of remaining time.\n",
            "\t-3.6945\t = Validation score   (log_loss)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 42.41s of the 42.38s of remaining time.\n",
            "\tTime limit exceeded... Skipping NeuralNetFastAI.\n",
            "Fitting model: LightGBMXT ... Training model for up to 14.62s of the 14.59s of remaining time.\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\tRan out of time, early stopping on iteration 253. Best iteration is:\n",
            "\t[248]\ttrain_set's multi_logloss: 0.599709\tvalid_set's multi_logloss: 0.806429\n",
            "\t-0.8064\t = Validation score   (log_loss)\n",
            "\t16.0s\t = Training   runtime\n",
            "\t0.64s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 43.05s of the -3.79s of remaining time.\n",
            "\t-0.7959\t = Validation score   (log_loss)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 65.19s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ws_run_result/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# テストデータを用いた推論\n",
        "休憩前に下記のlog_lossの表示のセルまで実行しておいてください！\n"
      ],
      "metadata": {
        "id": "LN6cfMJdEsjS"
      },
      "id": "LN6cfMJdEsjS"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O test.csv https://drive.google.com/uc?id=1eMQr4WoHAkYjjMeu8hkyuqqixru_r_Gl\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "fPoBrKR0EvVJ",
        "outputId": "fa35d4c9-c943-47ea-a7cf-5dcdee3a4162"
      },
      "id": "fPoBrKR0EvVJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-04 00:41:08--  https://drive.google.com/uc?id=1eMQr4WoHAkYjjMeu8hkyuqqixru_r_Gl\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.97.139, 108.177.97.102, 108.177.97.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.97.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-bg-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/aid5q9m6sqgsij9ttcaktd45qafsihq0/1643935200000/08554479401840081137/*/1eMQr4WoHAkYjjMeu8hkyuqqixru_r_Gl [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-02-04 00:41:09--  https://doc-0o-bg-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/aid5q9m6sqgsij9ttcaktd45qafsihq0/1643935200000/08554479401840081137/*/1eMQr4WoHAkYjjMeu8hkyuqqixru_r_Gl\n",
            "Resolving doc-0o-bg-docs.googleusercontent.com (doc-0o-bg-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
            "Connecting to doc-0o-bg-docs.googleusercontent.com (doc-0o-bg-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4756546 (4.5M) [text/csv]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>]   4.54M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-02-04 00:41:10 (116 MB/s) - ‘test.csv’ saved [4756546/4756546]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b30c59c-36bd-4402-a804-65e1baadfc99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ncode</th>\n",
              "      <th>general_firstup</th>\n",
              "      <th>title</th>\n",
              "      <th>story</th>\n",
              "      <th>keyword</th>\n",
              "      <th>userid</th>\n",
              "      <th>writer</th>\n",
              "      <th>biggenre</th>\n",
              "      <th>genre</th>\n",
              "      <th>novel_type</th>\n",
              "      <th>end</th>\n",
              "      <th>isstop</th>\n",
              "      <th>isr15</th>\n",
              "      <th>isbl</th>\n",
              "      <th>isgl</th>\n",
              "      <th>iszankoku</th>\n",
              "      <th>istensei</th>\n",
              "      <th>istenni</th>\n",
              "      <th>pc_or_k</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N8448DH</td>\n",
              "      <td>2016-05-21 20:05:13</td>\n",
              "      <td>前を</td>\n",
              "      <td>小さい時は色んな夢をみてました</td>\n",
              "      <td>愚詩集</td>\n",
              "      <td>819372</td>\n",
              "      <td>のいず</td>\n",
              "      <td>98</td>\n",
              "      <td>9801</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N8886GE</td>\n",
              "      <td>2020-05-01 16:23:47</td>\n",
              "      <td>紫電飛ぶ〜着陸失敗は嫌なので二段式引込み脚なんてやめちゃいます〜</td>\n",
              "      <td>「二段式引込み脚を」「断るッッ！！！」\\n\\nもしも紫電が着陸事故の原因となる二段式引込み脚を採用していなかったら……？というIF作品になります。</td>\n",
              "      <td>IF戦記 近代 昭和 ミリタリー 紫電 ジョージ</td>\n",
              "      <td>1459454</td>\n",
              "      <td>まきなみ</td>\n",
              "      <td>3</td>\n",
              "      <td>303</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b30c59c-36bd-4402-a804-65e1baadfc99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b30c59c-36bd-4402-a804-65e1baadfc99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b30c59c-36bd-4402-a804-65e1baadfc99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     ncode      general_firstup  ... istenni pc_or_k\n",
              "0  N8448DH  2016-05-21 20:05:13  ...       0       1\n",
              "1  N8886GE  2020-05-01 16:23:47  ...       0       2\n",
              "\n",
              "[2 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = predictor.predict_proba(test_df)"
      ],
      "metadata": {
        "id": "0J4_CjPaFDVX"
      },
      "id": "0J4_CjPaFDVX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard(silent=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Fzwuu85gFMWY",
        "outputId": "1231ddb7-e1c4-4e77-9e98-43384bebc01b"
      },
      "id": "Fzwuu85gFMWY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-089fdb39-4fc4-41e1-8d00-f4c90423060b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-0.795915</td>\n",
              "      <td>0.750900</td>\n",
              "      <td>16.903847</td>\n",
              "      <td>0.001688</td>\n",
              "      <td>0.727150</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>-0.806429</td>\n",
              "      <td>0.643082</td>\n",
              "      <td>16.001714</td>\n",
              "      <td>0.643082</td>\n",
              "      <td>16.001714</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNeighborsUnif</td>\n",
              "      <td>-2.909031</td>\n",
              "      <td>0.108539</td>\n",
              "      <td>0.172460</td>\n",
              "      <td>0.108539</td>\n",
              "      <td>0.172460</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNeighborsDist</td>\n",
              "      <td>-3.694488</td>\n",
              "      <td>0.106130</td>\n",
              "      <td>0.174983</td>\n",
              "      <td>0.106130</td>\n",
              "      <td>0.174983</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-089fdb39-4fc4-41e1-8d00-f4c90423060b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-089fdb39-4fc4-41e1-8d00-f4c90423060b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-089fdb39-4fc4-41e1-8d00-f4c90423060b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 model  score_val  ...  can_infer  fit_order\n",
              "0  WeightedEnsemble_L2  -0.795915  ...       True          4\n",
              "1           LightGBMXT  -0.806429  ...       True          3\n",
              "2       KNeighborsUnif  -2.909031  ...       True          1\n",
              "3       KNeighborsDist  -3.694488  ...       True          2\n",
              "\n",
              "[4 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(data = train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "PFnFXmn6FO4a",
        "outputId": "ffdcd7f7-97dc-477a-835c-bf763fe3ccb4"
      },
      "id": "PFnFXmn6FO4a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 19 features using 1000 rows with 3 shuffle sets...\n",
            "\t32.04s\t= Expected runtime (10.68s per shuffle set)\n",
            "\t20.84s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-987d770a-928f-4e5c-850c-e3923e46da88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>keyword</th>\n",
              "      <td>0.240356</td>\n",
              "      <td>0.006154</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275620</td>\n",
              "      <td>0.205091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userid</th>\n",
              "      <td>0.159330</td>\n",
              "      <td>0.007992</td>\n",
              "      <td>0.000419</td>\n",
              "      <td>3</td>\n",
              "      <td>0.205124</td>\n",
              "      <td>0.113536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre</th>\n",
              "      <td>0.124245</td>\n",
              "      <td>0.006175</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>3</td>\n",
              "      <td>0.159629</td>\n",
              "      <td>0.088862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>novel_type</th>\n",
              "      <td>0.083183</td>\n",
              "      <td>0.001911</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>3</td>\n",
              "      <td>0.094134</td>\n",
              "      <td>0.072232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>story</th>\n",
              "      <td>0.077266</td>\n",
              "      <td>0.007234</td>\n",
              "      <td>0.001455</td>\n",
              "      <td>3</td>\n",
              "      <td>0.118719</td>\n",
              "      <td>0.035814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>writer</th>\n",
              "      <td>0.054983</td>\n",
              "      <td>0.008123</td>\n",
              "      <td>0.003599</td>\n",
              "      <td>3</td>\n",
              "      <td>0.101530</td>\n",
              "      <td>0.008437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>general_firstup</th>\n",
              "      <td>0.029753</td>\n",
              "      <td>0.003933</td>\n",
              "      <td>0.002887</td>\n",
              "      <td>3</td>\n",
              "      <td>0.052287</td>\n",
              "      <td>0.007219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>biggenre</th>\n",
              "      <td>0.025982</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>3</td>\n",
              "      <td>0.033885</td>\n",
              "      <td>0.018079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isr15</th>\n",
              "      <td>0.006465</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.002605</td>\n",
              "      <td>3</td>\n",
              "      <td>0.011115</td>\n",
              "      <td>0.001815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>istensei</th>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.003498</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001180</td>\n",
              "      <td>0.000106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iszankoku</th>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.018112</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001483</td>\n",
              "      <td>-0.000475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isgl</th>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.057615</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001979</td>\n",
              "      <td>-0.001136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>istenni</th>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.080553</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001697</td>\n",
              "      <td>-0.001086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isbl</th>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000516</td>\n",
              "      <td>0.255607</td>\n",
              "      <td>3</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>-0.002721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pc_or_k</th>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.130478</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>-0.000911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isstop</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>end</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ncode</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-987d770a-928f-4e5c-850c-e3923e46da88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-987d770a-928f-4e5c-850c-e3923e46da88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-987d770a-928f-4e5c-850c-e3923e46da88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 importance    stddev   p_value  n  p99_high   p99_low\n",
              "keyword            0.240356  0.006154  0.000109  3  0.275620  0.205091\n",
              "userid             0.159330  0.007992  0.000419  3  0.205124  0.113536\n",
              "genre              0.124245  0.006175  0.000411  3  0.159629  0.088862\n",
              "novel_type         0.083183  0.001911  0.000088  3  0.094134  0.072232\n",
              "story              0.077266  0.007234  0.001455  3  0.118719  0.035814\n",
              "writer             0.054983  0.008123  0.003599  3  0.101530  0.008437\n",
              "general_firstup    0.029753  0.003933  0.002887  3  0.052287  0.007219\n",
              "biggenre           0.025982  0.001379  0.000469  3  0.033885  0.018079\n",
              "isr15              0.006465  0.000811  0.002605  3  0.011115  0.001815\n",
              "istensei           0.000643  0.000094  0.003498  3  0.001180  0.000106\n",
              "iszankoku          0.000504  0.000171  0.018112  3  0.001483 -0.000475\n",
              "isgl               0.000421  0.000272  0.057615  3  0.001979 -0.001136\n",
              "istenni            0.000306  0.000243  0.080553  3  0.001697 -0.001086\n",
              "isbl               0.000236  0.000516  0.255607  3  0.003193 -0.002721\n",
              "pc_or_k            0.000169  0.000188  0.130478  3  0.001248 -0.000911\n",
              "isstop             0.000000  0.000000  0.500000  3  0.000000  0.000000\n",
              "end                0.000000  0.000000  0.500000  3  0.000000  0.000000\n",
              "title              0.000000  0.000000  0.500000  3  0.000000  0.000000\n",
              "ncode              0.000000  0.000000  0.500000  3  0.000000  0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O seikai.csv https://drive.google.com/uc?id=1126wA1rX709MsYgVxxo8ALpKJbPXs0xe\n",
        "y_true = pd.read_csv('seikai.csv').drop(\"Unnamed: 0\",axis=1)\n",
        "y_true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "dQG7hddmFT5e",
        "outputId": "4e7420e1-f3aa-4f13-929b-a029072edbc6"
      },
      "id": "dQG7hddmFT5e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-04 00:46:05--  https://drive.google.com/uc?id=1126wA1rX709MsYgVxxo8ALpKJbPXs0xe\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.8.139, 142.251.8.138, 142.251.8.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.8.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-bg-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/n6d4k3e9prth8i82i76iei6n4oiju4n2/1643935500000/08554479401840081137/*/1126wA1rX709MsYgVxxo8ALpKJbPXs0xe [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-02-04 00:46:05--  https://doc-0s-bg-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/n6d4k3e9prth8i82i76iei6n4oiju4n2/1643935500000/08554479401840081137/*/1126wA1rX709MsYgVxxo8ALpKJbPXs0xe\n",
            "Resolving doc-0s-bg-docs.googleusercontent.com (doc-0s-bg-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
            "Connecting to doc-0s-bg-docs.googleusercontent.com (doc-0s-bg-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118901 (116K) [application/octet-stream]\n",
            "Saving to: ‘seikai.csv’\n",
            "\n",
            "seikai.csv          100%[===================>] 116.11K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2022-02-04 00:46:05 (12.0 MB/s) - ‘seikai.csv’ saved [118901/118901]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-05081294-87c3-4860-bb16-65cf666d76f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05081294-87c3-4860-bb16-65cf666d76f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05081294-87c3-4860-bb16-65cf666d76f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05081294-87c3-4860-bb16-65cf666d76f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0  1  2  3  4\n",
              "0     1  0  0  0  0\n",
              "1     0  1  0  0  0\n",
              "2     0  0  0  1  0\n",
              "3     0  1  0  0  0\n",
              "4     0  1  0  0  0\n",
              "...  .. .. .. .. ..\n",
              "7995  1  0  0  0  0\n",
              "7996  0  1  0  0  0\n",
              "7997  0  1  0  0  0\n",
              "7998  0  1  0  0  0\n",
              "7999  0  1  0  0  0\n",
              "\n",
              "[8000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_true, y_prob) # ここの値をFormsに投稿お願いします！"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6XwRGJZFVr1",
        "outputId": "36a82694-be4a-4814-9f25-12682a0ec23e"
      },
      "id": "d6XwRGJZFVr1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7942650730706519"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0bace70",
      "metadata": {
        "id": "d0bace70"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "fit関数のオプションについて\n",
        "\n",
        "```\n",
        "============ fit kwarg info ============\n",
        "User Specified kwargs:\n",
        "{}\n",
        "Full kwargs:\n",
        "{'_feature_generator_kwargs': None,\n",
        " '_save_bag_folds': None,\n",
        " 'ag_args': None,\n",
        " 'ag_args_ensemble': None,\n",
        " 'ag_args_fit': None,\n",
        " 'auto_stack': False,\n",
        " 'excluded_model_types': None,\n",
        " 'feature_generator': 'auto',\n",
        " 'holdout_frac': None,\n",
        " 'hyperparameter_tune_kwargs': None,\n",
        " 'keep_only_best': False,\n",
        " 'num_bag_folds': None,\n",
        " 'num_bag_sets': None,\n",
        " 'num_stack_levels': None,\n",
        " 'quantile_levels': None,\n",
        " 'refit_full': False,\n",
        " 'save_space': False,\n",
        " 'set_best_to_refit_full': False,\n",
        " 'unlabeled_data': None,\n",
        " 'use_bag_holdout': False,\n",
        " 'verbosity': 3}\n",
        "========================================\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vOsJeQ3R2bbQ"
      },
      "id": "vOsJeQ3R2bbQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "WS.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bedd2a8195cd453b8fe3d9225b7ccf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ba30fda63404defb67f7044b7ad3f7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b9964204895497ebf1ec4c89f860190",
              "IPY_MODEL_0aff0a95f2ba425f8afa97b92eeb3949",
              "IPY_MODEL_834076516b4d4506aa78af563ecb97d1"
            ]
          }
        },
        "1ba30fda63404defb67f7044b7ad3f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b9964204895497ebf1ec4c89f860190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26e7d192ede54bd39e66bc105014c307",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  3%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef4ab6f193ac4e9fa76fe2b976865a81"
          }
        },
        "0aff0a95f2ba425f8afa97b92eeb3949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5afeea8fdac94c2cacc9e5b4df0eb49f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 30,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_968f3075b3a94eed9841e826d4069090"
          }
        },
        "834076516b4d4506aa78af563ecb97d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7e4704d29514a87b3a208446384954c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/30 [00:13&lt;03:13,  6.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4de816cba798428590c7b4d4a2da29a6"
          }
        },
        "26e7d192ede54bd39e66bc105014c307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef4ab6f193ac4e9fa76fe2b976865a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5afeea8fdac94c2cacc9e5b4df0eb49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "968f3075b3a94eed9841e826d4069090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7e4704d29514a87b3a208446384954c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4de816cba798428590c7b4d4a2da29a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9ff3ecbd7a04381bb343dce896b1e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_515feec3b9b948d88af2ca588496e522",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b0a7ec5be4514fc09ef93dceaaa4c4bc",
              "IPY_MODEL_52520fba8ef7443d87c1034ff64ef6da",
              "IPY_MODEL_37ccbd298f5643408b281ec034746f36"
            ]
          }
        },
        "515feec3b9b948d88af2ca588496e522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0a7ec5be4514fc09ef93dceaaa4c4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7745f060736b4ef5992a464d7a4c1dd2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db6d3bab50774c1d818ef091d9aa644c"
          }
        },
        "52520fba8ef7443d87c1034ff64ef6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1675b1ccc1e84ee9a18eec88ae84ecc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 30,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f018f5d1248c413f8bb75c9c0ddc6112"
          }
        },
        "37ccbd298f5643408b281ec034746f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61aadf5642d24e45bb65bcfe6000f21b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/30 [00:13&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21d55374ea8d457487960cad7bc1b101"
          }
        },
        "7745f060736b4ef5992a464d7a4c1dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db6d3bab50774c1d818ef091d9aa644c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1675b1ccc1e84ee9a18eec88ae84ecc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f018f5d1248c413f8bb75c9c0ddc6112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61aadf5642d24e45bb65bcfe6000f21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21d55374ea8d457487960cad7bc1b101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}